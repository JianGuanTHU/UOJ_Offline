#!/usr/bin/env python
#coding=utf-8

import sys
import os

import judger_class_lib as lib
from uoj_judger_compiler import *
from uoj_judger_tester import *
from uoj_judger_reporter import *
from uoj_judger_config import *

def check(n, file_name, answer_file):

	valid_flag = []
	valid_info = []
	final_flag = []
	final_info = []

	f = open(file_name)
	ans = open(answer_file)
	lines = f.readlines()
	ans_lines = ans.readlines()
	#if len(lines) < n:
	#	return False, "Only %d lines, < %d" % (len(lines), n), final_flag, final_info
	
	for i in range(n):
	
		if len(lines) <= i:
			valid_flag.append(False)
			valid_info.append("Only %d lines, < %d" % (len(lines), n))
			final_flag.append(False)
			final_info.append("Only %d lines, < %d" % (len(lines), n))
			continue
		
		select = set()
		answer = []
		
		flag = False
		for c in lines[i].strip():
			if c in "ABCD":
				select.add(c)
			else:
				valid_flag.append(False)
				valid_info.append("Invalid token %c at line %d" % (c, i + 1))
				final_flag.append(False)
				final_info.append("Invalid token %c at line %d" % (c, i + 1))
				flag=True
				break
		if flag:
			continue

		now = set()
		for c in ans_lines[i].strip():
			if c in "ABCD":
				now.add(c)
			elif c == '|':
				answer.append(now)
				now = set()
		if len(now) > 0:
			answer.append(now)
		
		valid_flag.append(True)
		valid_info.append("Valid answer: %s" % sorted(list(select)))
		if sum([(select == ans) for ans in answer]) > 0:
			final_flag.append(True)
			final_info.append("ok")
		else:
			final_flag.append(False)
			final_info.append("Wrong Answer at line %d" % (i+1))
	return valid_flag, valid_info, final_flag, final_info		

if __name__=="__main__":
	main_path = sys.argv[1]
	work_path = sys.argv[2]
	result_path = sys.argv[3]
	data_path = sys.argv[4]

	C = pyjudgerConfig(main_path, work_path, result_path, data_path)
	n = int(C.config["n_tests"])
	R = pyjudgerReporter(C, n)
	Co = pyjudgerCompiler(C)
	T = pyjudger_custom_tester(C)

	R.report_judgement_status("Judging")
	
	#try:
	valid, valid_info, final, final_info = check(n, work_path+"/answer.txt", data_path+"/answer.txt")
		
	for i in range(n):
		if "test_sample_only" in C.config:
			if valid[i]:
				R.add_point_info(lib.PointInfo(i+1, 100, info="Acceptable Answer", res=valid_info[i]))
			else:
				R.add_point_info(lib.PointInfo(i+1, 0, info="Invalid Answer", res=valid_info[i]))
		else:
			if final[i]:
				R.add_point_info(lib.PointInfo(i+1, 100, info="Accepted", res=final_info[i]))
			else:
				R.add_point_info(lib.PointInfo(i+1, 0, info="Wrong Answer", res=final_info[i]))
	R.end_judge_ok()
	#except:
	#	R.end_judge_judgement_failed()
